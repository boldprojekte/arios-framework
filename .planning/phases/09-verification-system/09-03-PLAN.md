---
phase: 09-verification-system
plan: 03
type: execute
wave: 3
depends_on: ["09-02"]
files_modified:
  - packages/arios-cli/templates/.claude/commands/arios/orchestrate.md
autonomous: true

must_haves:
  truths:
    - "User reviews and tests the built feature at phase end"
    - "User receives specific test instructions for what to verify"
    - "User can report issues via chat and trigger new repair cycle"
    - "Phase does not complete until user approves"
  artifacts:
    - path: "packages/arios-cli/templates/.claude/commands/arios/orchestrate.md"
      provides: "Phase-end human review flow"
      contains: "Phase Complete - Review Required"
  key_links:
    - from: "orchestrate.md"
      to: "User"
      via: "Test instructions and approval prompt"
      pattern: "Please test and type"
---

<objective>
Add phase-end human review flow to orchestrator. After all waves complete, user reviews what was built with specific test instructions. User approves to complete phase or reports issues to trigger new repair cycle.

Purpose: Human verification at meaningful checkpoints (phase boundaries)
Output: Updated orchestrate.md with phase completion human review
</objective>

<execution_context>
@/Users/j.franke/.claude/get-shit-done/workflows/execute-plan.md
@/Users/j.franke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-verification-system/09-CONTEXT.md
@.planning/phases/09-verification-system/09-RESEARCH.md
@packages/arios-cli/templates/.claude/commands/arios/orchestrate.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add phase completion human review section</name>
  <files>packages/arios-cli/templates/.claude/commands/arios/orchestrate.md</files>
  <action>
Add a new section "## Phase Completion - Human Review" after the "## Wave Verification" section.

**New section content:**

```markdown
## Phase Completion - Human Review

**Purpose:** After all waves complete, user reviews and tests what was built. This is the 3rd tier of verification (phase level).

**When:** After the last wave passes verification.

**Why human review matters:**
- Automated checks catch syntax, type errors, and integration gaps
- Only humans can verify: Does this FEEL right? Is the UX good? Does it solve the problem?
- Prevents building more features on a shaky foundation

### 1. Generate Phase Summary

Collect from all plan SUMMARYs:
- Total plans completed
- Total commits made
- Files created/modified (aggregated list)
- Any warnings logged during verification

### 2. Generate Test Instructions

**Adapt detail level to feature complexity:**

For simple features (1-2 plans, UI changes):
```
### Test Instructions
1. Start the app: `npm run dev`
2. Navigate to {specific page}
3. Verify: {expected behavior}
```

For complex features (3+ plans, multiple subsystems):
```
### Test Instructions

**Setup:**
1. Start the app: `npm run dev`
2. Open browser to http://localhost:3000

**Test Scenario 1: {scenario name}**
1. {Step 1}
2. {Step 2}
Expected: {what should happen}

**Test Scenario 2: {scenario name}**
1. {Step 1}
2. {Step 2}
Expected: {what should happen}

**Edge Cases to Check:**
- {edge case 1}
- {edge case 2}
```

**Generating specific instructions:**
- Read plan objectives to understand what was built
- Identify user-facing entry points (pages, buttons, commands)
- Map to testable scenarios
- Include expected behavior for each step

### 3. Present to User

```markdown
## Phase {N} Complete - Review Required

**Built:** {summary of what was created}
**Plans:** {count} plans executed
**Tests:** All passing

### What's New
{Brief description of features added}

### Test Instructions
{Generated test instructions from step 2}

---

Please test and let me know:
- Type "approved" if everything works
- Or describe any issues you find
```

### 4. Handle User Response

**If user types "approved" (or similar affirmative):**
- Mark phase as complete in STATE.md
- Display: "Phase {N} approved. Ready for next phase."
- Suggest: `/arios` to continue or `/clear` for context reset

**If user reports issues:**
```
Parse user's issue description:
- What's not working?
- What was expected vs actual?

Spawn recovery-agent with:
<failure_context>
type: verification_failure
wave: final
plan_id: user_reported
attempt: 1
error: {user's issue description}
files_affected: [relevant files based on issue]
recent_commits: [commits from this phase]
</failure_context>

After recovery completes:
- Re-run affected verification checks
- Present updated test instructions
- Ask user to re-verify

Maximum 3 recovery attempts per reported issue.
If still failing: ask user for more detail or offer to continue anyway.
```

**If user asks questions (not reporting issue):**
- Answer the question based on plan context
- Re-present the approval prompt
```
  </action>
  <verify>
Section exists: `grep "Phase Completion - Human Review" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md`
Test instructions: `grep "Test Instructions" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md`
Approval handling: `grep "approved" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md`
  </verify>
  <done>orchestrate.md has Phase Completion section with test instruction generation and approval handling</done>
</task>

<task type="auto">
  <name>Task 2: Update report section for 3-tier verification model</name>
  <files>packages/arios-cli/templates/.claude/commands/arios/orchestrate.md</files>
  <action>
Update the existing "## Report" section to reflect the 3-tier verification model.

**Replace the "On completion" and "On failure" templates with:**

```markdown
## Report

**During execution (per wave):**
```
Starting wave {N} ({count} plans)
[execution happens]
Wave {N} complete: {passed}/{total} plans passed
[verification runs silently]
```

**After all waves (phase review):**
```
## Phase {N} Complete - Review Required

**Built:** {features summary}
**Plans:** {count} plans executed
**Tests:** {pass count}/{total} passing

### What's New
- {feature 1}
- {feature 2}

### Test Instructions
{specific test steps}

Please test and type "approved" or describe issues.
```

**On user approval:**
```
Phase {N} approved.

Dashboard: http://localhost:3456 (for detailed review)

Next: {suggested action based on roadmap}
Tip: Consider `/clear` before next phase for fresh context.
```

**On wave verification failure (after recovery exhausted):**
```
## Wave {N} Verification Failed

Attempted 3 auto-fixes without success.
Issue: {brief description}

Options:
(d) Debug - I'll investigate further
(s) Skip - Continue anyway (if no downstream deps)
(a) Abort - Stop execution, preserve state
```

**On user-reported issue (after recovery exhausted):**
```
## Unable to Auto-Fix Reported Issue

Attempted 3 fixes for: "{user's issue description}"

Latest attempt result: {what was tried}

Options:
- Provide more details about the issue
- Type "continue" to proceed anyway
- Type "abort" to stop and investigate manually
```
```

**Also add a note about the 3-tier model:**

```markdown
### Verification Tiers (3-tier model)

| Tier | When | What | User Sees |
|------|------|------|-----------|
| Auto | During task | Syntax, compile, verify step | Only failures |
| Wave | Between waves | npm scripts, code review, integration | Only failures |
| Phase | After all waves | Human testing and approval | Always |

**Philosophy:** Machines verify what machines can verify. Humans verify what matters to humans.
```
  </action>
  <verify>
Verification tiers documented: `grep "Verification Tiers" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md`
User approval message: `grep "Phase.*approved" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md`
Three tiers mentioned: `grep -E "Auto|Wave|Phase" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md | head -5`
  </verify>
  <done>Report section updated with 3-tier verification model documentation and all message templates</done>
</task>

</tasks>

<verification>
- orchestrate.md has "## Phase Completion - Human Review" section
- Test instructions are generated based on feature complexity
- User can approve with "approved" keyword
- User-reported issues trigger recovery-agent
- Report section documents all three verification tiers
- Message templates exist for all scenarios (approval, wave failure, user issue)
</verification>

<success_criteria>
1. User sees human review prompt after all waves complete
2. Test instructions are specific (not just "check if it works")
3. User can approve to complete phase
4. User can report issues to trigger repair cycle
5. All three verification tiers are documented
6. User always knows what phase is doing and why
</success_criteria>

<output>
After completion, create `.planning/phases/09-verification-system/09-03-SUMMARY.md`
</output>
