---
phase: 08-parallel-execution
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/arios-cli/templates/.claude/agents/recovery-agent.md
  - packages/arios-cli/templates/.claude/commands/arios/orchestrate.md
autonomous: true

must_haves:
  truths:
    - "Single recovery agent handles both task failures and verification issues"
    - "Auto-retry up to 3 times before prompting user"
    - "Skip option only offered if no downstream dependencies"
  artifacts:
    - path: "packages/arios-cli/templates/.claude/agents/recovery-agent.md"
      provides: "Unified recovery agent prompt"
      min_lines: 50
    - path: "packages/arios-cli/templates/.claude/commands/arios/orchestrate.md"
      provides: "Recovery agent spawning"
      contains: "recovery-agent.md"
  key_links:
    - from: "orchestrate.md"
      to: "recovery-agent.md"
      via: "Task tool on failure"
      pattern: "spawn.*recovery-agent"
---

<objective>
Create unified recovery agent that handles both task failures and verification issues.

Purpose: Single recovery pattern for all failure types per CONTEXT.md decision - "same core pattern: something went wrong, diagnose, fix."

Output: recovery-agent.md agent prompt, updated orchestrate.md with unified recovery flow
</objective>

<execution_context>
@/Users/j.franke/.claude/get-shit-done/workflows/execute-plan.md
@/Users/j.franke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-parallel-execution/08-CONTEXT.md
@.planning/phases/08-parallel-execution/08-RESEARCH.md
@packages/arios-cli/src/execution/recovery.ts
@packages/arios-cli/templates/.claude/commands/arios/orchestrate.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create unified recovery agent prompt</name>
  <files>packages/arios-cli/templates/.claude/agents/recovery-agent.md</files>
  <action>
Create the recovery agent that handles both task failures and verification failures.

Per CONTEXT.md: "Single recovery agent handles both task failures AND verification issues (not separate agents). Same core pattern - something went wrong, diagnose, fix."

Structure:
```markdown
---
name: recovery-agent
description: Handles both task execution failures and verification failures. Unified recovery pattern.
tools: Read, Write, Edit, Bash, Grep, Glob
model: sonnet
---

<role>
You are an ARIOS recovery agent. You diagnose and fix failures during execution.

**Unified recovery pattern:** Both failure types follow the same core loop:
1. Analyze what went wrong
2. Identify root cause
3. Apply fix
4. Verify fix works

You handle TWO failure types:
- **task_failure:** Code errors, build failures, test failures during plan execution
- **verification_failure:** Issues found by verifier between waves (stubs, wiring gaps)

The orchestrator provides failure context in your prompt. Your job: fix it.
</role>

<input>
From orchestrator (inlined in prompt):

<failure_context>
type: {task_failure | verification_failure}
wave: {N}
plan_id: {phase-plan}
attempt: {1-3}
error: {error message or verification gap description}
files_affected: [list of files]
recent_commits: [list of recent commits for context]
</failure_context>
</input>

<workflow>
**For task_failure:**
1. Parse error message to identify failure type (compile, runtime, test)
2. Read the affected file(s)
3. Identify root cause:
   - Missing import?
   - Type mismatch?
   - Logic error?
   - Missing dependency?
4. Apply fix (use Edit tool for precision)
5. Verify fix: run the command that originally failed
6. If fix works: commit with format `fix({phase}-{plan}): {description}`
7. Return result

**For verification_failure:**
1. Parse gap description (stub detection, wiring missing, key_link broken)
2. Read the affected file(s)
3. Identify what's missing:
   - Stub needs real implementation?
   - API endpoint not wired?
   - Component not connected to data?
4. Apply fix (often involves multiple files)
5. Verify fix: run verification check that originally failed
6. If fix works: commit with format `fix({phase}): {description}`
7. Return result

**If fix cannot be applied:**
- Record detailed diagnosis
- Explain WHY fix couldn't be applied
- Suggest what user needs to do
- Return RECOVERY FAILED
</workflow>

<output>
## RECOVERY COMPLETE

**Type:** {task_failure | verification_failure}
**Fixed:** true
**Diagnosis:** {what was wrong}
**Fix:** {what was done}
**Commits:** [{commit hash}]

OR

## RECOVERY FAILED

**Type:** {task_failure | verification_failure}
**Attempt:** {N}
**Diagnosis:** {what was found}
**Blocker:** {why fix couldn't be applied}
**Suggestion:** {what user should do}
</output>
```

Key differences from the existing debug pattern in recovery.ts:
- Unified agent (not separate debug vs verification agents)
- Receives full context inlined (not @-references)
- Returns structured result for orchestrator parsing
- Includes commit step on success
  </action>
  <verify>cat packages/arios-cli/templates/.claude/agents/recovery-agent.md && grep -q "task_failure" packages/arios-cli/templates/.claude/agents/recovery-agent.md && grep -q "verification_failure" packages/arios-cli/templates/.claude/agents/recovery-agent.md</verify>
  <done>recovery-agent.md handles both failure types with unified pattern</done>
</task>

<task type="auto">
  <name>Task 2: Update orchestrator failure handling with recovery agent</name>
  <files>packages/arios-cli/templates/.claude/commands/arios/orchestrate.md</files>
  <action>
Update the orchestrator's failure handling to use the new unified recovery agent.

Changes to make:

1. **Update "Checkpoint Verification" section step 3** to use recovery-agent.md:

Replace the existing "Spawn debug subagent" pattern with:
```markdown
3. **If checkpoint fails - trigger recovery flow:**

   a. **First attempt automatic recovery (max 3 attempts):**

      For attempt = 1 to 3:
        - Display: "Recovery attempt {attempt}/3..."
        - Spawn unified recovery agent:
          ```
          Use Task tool to spawn .claude/agents/recovery-agent.md

          <failure_context>
          type: task_failure
          wave: {N}
          plan_id: {phase-plan}
          attempt: {attempt}
          error: {checkpoint_error_output}
          files_affected: [files modified in this wave]
          recent_commits: [commits from this wave]
          </failure_context>
          ```
        - Parse recovery agent return message
        - If "RECOVERY COMPLETE" with "Fixed: true":
            - Re-run checkpoint verification
            - If passes: break, continue to next wave
        - If "RECOVERY FAILED":
            - Continue to next attempt
```

2. **Add new section "### Spawning Recovery Agent":**

```markdown
### Spawning Recovery Agent

**Used for:** Both task failures during execution AND verification failures between waves.

**Pre-spawn context gathering:**
1. Collect error/gap details
2. List files affected
3. Get recent commits for context
4. Determine failure type (task_failure or verification_failure)

**Display announcement:**
```
## Delegating to Recovery Agent

**Purpose:** Diagnose and fix {failure type}
**Scope:** {affected files}
**Attempt:** {N}/3

Spawning recovery agent...
```

**Then use Task tool:**
```
Use Task tool to spawn .claude/agents/recovery-agent.md

<failure_context>
type: {task_failure | verification_failure}
wave: {N}
plan_id: {phase-plan or "verification"}
attempt: {attempt}
error: {error details}
files_affected: [list]
recent_commits: [list]
</failure_context>
```

**After recovery agent returns:**
Parse return message:
- Look for "## RECOVERY COMPLETE" or "## RECOVERY FAILED"
- Extract Fixed status
- Extract diagnosis and fix description
```

3. **Update user prompt on exhaustion** to check downstream dependencies:

```markdown
b. **If all recovery attempts exhausted (3/3 failed):**
   ...
   - Check if failed plan has downstream dependencies:
     - Parse PLAN.md frontmatter for plans that depend_on this plan
     - If no downstream dependencies: offer Skip option
     - If has downstream dependencies: NO Skip option (would cascade)

   - Prompt user:
     If no downstream deps:
       "Task {X} failed 3x: [error]. Options: Debug (d), Skip (s), Abort (a)"
     If has downstream deps:
       "Task {X} failed 3x: [error]. Cannot skip (downstream tasks depend on it). Options: Debug (d), Abort (a)"
```

This unifies the failure handling around the new recovery-agent.md.
  </action>
  <verify>grep -q "recovery-agent.md" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md && grep -q "downstream dependencies" packages/arios-cli/templates/.claude/commands/arios/orchestrate.md</verify>
  <done>orchestrate.md uses unified recovery-agent.md and checks downstream dependencies</done>
</task>

</tasks>

<verification>
1. recovery-agent.md exists with unified handling for task_failure and verification_failure
2. orchestrate.md references recovery-agent.md (not generic debug subagent)
3. orchestrate.md checks downstream dependencies before offering Skip option
4. Both files committed
</verification>

<success_criteria>
- recovery-agent.md handles both failure types
- orchestrate.md spawns recovery-agent.md for failures
- Skip option conditional on downstream dependencies
- 3-attempt limit maintained
</success_criteria>

<output>
After completion, create `.planning/phases/08-parallel-execution/08-02-SUMMARY.md`
</output>
